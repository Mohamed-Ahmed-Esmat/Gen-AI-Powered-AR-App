## Contents

The following notebooks are included in this directory:
1. [`3d-Pix3pix.ipynb`](3DPix2Pix/3d-pix3pix.ipynb): Implementatation and training of 3D-Pix2Pix with a U-Net Generator and a Patch Discriminator.
2. [`Pix3Pix.ipynb`](3DPix2Pix/Pix3Pix.ipynb): Implementation and training of the final version of 3D-Pix2Pix that is working as well as results
3. [`image2vox-model.ipynb`](Pix2Vox/image2vox-model.ipynb): Implementation and training of Pix2Vox.
4.  [`Pix2Vox-Pretrained-A.ipynb`](Pix2Vox/Pix2Vox-Pretrained-A.ipynb): Inference of the pretrained `Pix2Vox-A` version.
5. [`pretrained-pix2vox-F.ipynb`](Pix2Vox/pretrained-pix2vox-F.ipynb): Inference of the pretrained `Pix2Vox-F` version.
6. [`dcgan-cls.ipynb`](Text2Image/dcgan-cls.ipynb): Implementation of a Text-To-Image cGAN, leveraging text descriptions as conditioning inputs to generate corresponding images.
7. [`dcgan-cls_one_Cat.ipynb`](Text2Image/dcgan-cls_one_Cat.ipynb): Implementation of a Text-To-Image cGAN on one category of images due to lack of resources.
8. [`Notebooks/PIFuHD/`](PIFuHD): Exploring PIFuHD from [Meta Research](https://github.com/facebookresearch) for High-Resolution 3D Human Digitization.
9. [`mesh-reconstruction-pytorch3d.ipynb`](Mesh-Reconstruction/mesh-reconstruction-pytorch3d.ipynb): Exploring Pytorch3D from [Meta Research](https://github.com/facebookresearch).


